{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow tensorflow_hub librosa pandas scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cấu hình\n",
    "SAMPLE_RATE_YAMNET = 16000\n",
    "SAMPLE_RATE_TRAIN = 32000\n",
    "WINDOW_SIZE = 0.96\n",
    "STRIDE = 0.1\n",
    "SIMILARITY_THRESHOLD = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_MATCH_PATH = \"/kaggle/input/audio-dataset/full_match.wav\" \n",
    "TEMPLATE_PATHS = [\n",
    "    \"/kaggle/input/audio-dataset/cut.wav\",\n",
    "    \"/kaggle/input/audio-dataset/cut1.wav\"\n",
    "]\n",
    "\n",
    "# Output folders\n",
    "OUTPUT_BASE = \"/kaggle/working/pickleball_dataset\"\n",
    "MIC_DIR = os.path.join(OUTPUT_BASE, \"mic_dev\")\n",
    "META_DIR = os.path.join(OUTPUT_BASE, \"metadata_dev\")\n",
    "\n",
    "os.makedirs(MIC_DIR, exist_ok=True)\n",
    "os.makedirs(META_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Đã setup xong môi trường.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YAMNet từ TF Hub\n",
    "print(\"Đang load YAMNet...\")\n",
    "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "print(\"Đã load YAMNet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(waveform):\n",
    "    \"\"\"Lấy vector đặc trưng 1024 chiều từ đoạn âm thanh\"\"\"\n",
    "    scores, embeddings, spectrogram = yamnet_model(waveform)\n",
    "    \n",
    "    if len(embeddings) > 0:\n",
    "        return np.mean(embeddings.numpy(), axis=0).reshape(1, -1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_templates(template_paths):\n",
    "    \"\"\"Tạo danh sách embedding từ các file mẫu\"\"\"\n",
    "    templates = []\n",
    "    for path in template_paths:\n",
    "        try:\n",
    "            wav, _ = librosa.load(path, sr=SAMPLE_RATE_YAMNET, mono=True)\n",
    "            \n",
    "            if len(wav) > int(WINDOW_SIZE * SAMPLE_RATE_YAMNET):\n",
    "                center = np.argmax(np.abs(wav))\n",
    "                start = max(0, center - int(0.48 * SAMPLE_RATE_YAMNET))\n",
    "                end = start + int(WINDOW_SIZE * SAMPLE_RATE_YAMNET)\n",
    "                wav = wav[start:end]\n",
    "            \n",
    "            if len(wav) < int(WINDOW_SIZE * SAMPLE_RATE_YAMNET):\n",
    "                wav = np.pad(wav, (0, int(WINDOW_SIZE * SAMPLE_RATE_YAMNET) - len(wav)))\n",
    "                \n",
    "            emb = get_embedding(wav)\n",
    "            if emb is not None:\n",
    "                templates.append(emb)\n",
    "                print(f\"  + Đã trích xuất đặc trưng mẫu: {os.path.basename(path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  x Lỗi file {path}: {e}\")\n",
    "            \n",
    "    return templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_match(full_audio, sr, templates, threshold=0.7):\n",
    "    \"\"\"Quét toàn bộ trận đấu để tìm vị trí giống mẫu\"\"\"\n",
    "    detected_times = []\n",
    "    \n",
    "    win_len = int(WINDOW_SIZE * sr)\n",
    "    stride_len = int(STRIDE * sr)\n",
    "    \n",
    "    num_steps = (len(full_audio) - win_len) // stride_len\n",
    "    \n",
    "    print(f\"Bắt đầu quét {len(full_audio)/sr:.1f} giây ({num_steps} bước)...\")\n",
    "    \n",
    "    scores_over_time = []\n",
    "    \n",
    "    # 1. Quét thô (Coarse Scan)\n",
    "    for i in tqdm(range(num_steps)):\n",
    "        start_sample = i * stride_len\n",
    "        end_sample = start_sample + win_len\n",
    "        chunk = full_audio[start_sample:end_sample]\n",
    "        \n",
    "        emb = get_embedding(chunk)\n",
    "        \n",
    "        if emb is not None:\n",
    "            # So sánh với tất cả templates, lấy điểm cao nhất\n",
    "            max_sim = 0\n",
    "            for t_emb in templates:\n",
    "                sim = cosine_similarity(t_emb, emb)[0][0]\n",
    "                if sim > max_sim:\n",
    "                    max_sim = sim\n",
    "            \n",
    "            scores_over_time.append(max_sim)\n",
    "            \n",
    "            # Nếu vượt ngưỡng, lưu lại thời gian thô\n",
    "            if max_sim >= threshold:\n",
    "                detected_times.append({\n",
    "                    'time': i * STRIDE,\n",
    "                    'score': max_sim,\n",
    "                    'chunk': chunk\n",
    "                })\n",
    "        else:\n",
    "            scores_over_time.append(0)\n",
    "            \n",
    "    return detected_times, np.array(scores_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Templates\n",
    "print(\"--- Xử lý file mẫu ---\")\n",
    "template_embeddings = extract_templates(TEMPLATE_PATHS)\n",
    "\n",
    "if not template_embeddings:\n",
    "    raise ValueError(\"Không tạo được mẫu nào. Kiểm tra lại file input!\")\n",
    "\n",
    "# 2. Load Full Match\n",
    "print(\"\\n--- Load trận đấu ---\")\n",
    "y_full, _ = librosa.load(FULL_MATCH_PATH, sr=SAMPLE_RATE_YAMNET, mono=True)\n",
    "\n",
    "# 3. Quét\n",
    "print(\"\\n--- Scanning... ---\")\n",
    "raw_hits, score_arr = scan_match(y_full, SAMPLE_RATE_YAMNET, template_embeddings, threshold=SIMILARITY_THRESHOLD)\n",
    "\n",
    "print(f\"\\nFound {len(raw_hits)} potential segments.\")\n",
    "\n",
    "# 4. Tinh chỉnh (Refinement) & Lọc trùng (NMS)\n",
    "print(\"\\n--- Tinh chỉnh vị trí (Peak Picking) ---\")\n",
    "\n",
    "final_labels = []\n",
    "last_hit_time = -100\n",
    "\n",
    "raw_hits.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "for hit in raw_hits:\n",
    "    coarse_time = hit['time']\n",
    "    \n",
    "    is_duplicate = False\n",
    "    for existing in final_labels:\n",
    "        if abs(existing['start'] - coarse_time) < 0.5:\n",
    "            is_duplicate = True\n",
    "            break\n",
    "    if is_duplicate:\n",
    "        continue\n",
    "        \n",
    "    # Tinh chỉnh: Tìm đỉnh năng lượng (Onset) trong đoạn 0.96s\n",
    "    chunk = hit['chunk']\n",
    "    onset_env = librosa.onset.onset_strength(y=chunk, sr=SAMPLE_RATE_YAMNET)\n",
    "    \n",
    "    local_peaks = librosa.util.peak_pick(onset_env, pre_max=3, post_max=3, pre_avg=3, post_avg=5, delta=0.5, wait=10)\n",
    "    \n",
    "    if len(local_peaks) > 0:\n",
    "        # Lấy peak cao nhất\n",
    "        best_peak_idx = local_peaks[np.argmax(onset_env[local_peaks])]\n",
    "        offset_time = librosa.frames_to_time(best_peak_idx, sr=SAMPLE_RATE_YAMNET)\n",
    "        exact_time = coarse_time + offset_time\n",
    "    else:\n",
    "        # Nếu không tìm thấy đỉnh rõ ràng, lấy giữa đoạn\n",
    "        exact_time = coarse_time + (WINDOW_SIZE / 2)\n",
    "        \n",
    "    # Tạo label (độ rộng 0.15s)\n",
    "    label_entry = {\n",
    "        'class': 'hit',\n",
    "        'start': round(exact_time - 0.075, 3),\n",
    "        'end': round(exact_time + 0.075, 3),\n",
    "        'ele': 0,\n",
    "        'azi': 0,\n",
    "        'score': hit['score']\n",
    "    }\n",
    "    final_labels.append(label_entry)\n",
    "\n",
    "# Sắp xếp lại theo thời gian\n",
    "final_labels.sort(key=lambda x: x['start'])\n",
    "\n",
    "print(f\"Kết quả cuối cùng: {len(final_labels)} cú đánh được phát hiện.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Tạo Dataset Files ---\")\n",
    "\n",
    "base_name = \"generated_match_01\"\n",
    "\n",
    "# 1. Lưu CSV\n",
    "df = pd.DataFrame(final_labels)\n",
    "if not df.empty:\n",
    "    csv_path = os.path.join(META_DIR, f\"{base_name}.csv\")\n",
    "    df[['class', 'start', 'end', 'ele', 'azi']].to_csv(csv_path, index=False)\n",
    "    print(f\"Đã lưu Metadata: {csv_path}\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"Không tìm thấy cú đánh nào! Hãy thử giảm SIMILARITY_THRESHOLD.\")\n",
    "\n",
    "# 2. Lưu Audio\n",
    "wav_out_path = os.path.join(MIC_DIR, f\"{base_name}.wav\")\n",
    "print(f\"Đang xử lý và lưu Audio (32kHz)...\")\n",
    "\n",
    "y_high, _ = librosa.load(FULL_MATCH_PATH, sr=SAMPLE_RATE_TRAIN, mono=True)\n",
    "sf.write(wav_out_path, y_high, SAMPLE_RATE_TRAIN)\n",
    "\n",
    "print(f\"Đã lưu Audio: {wav_out_path}\")\n",
    "\n",
    "!zip -r pickleball_dataset.zip {OUTPUT_BASE}\n",
    "print(\"\\nXONG! Bạn có thể download file pickleball_dataset.zip\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
